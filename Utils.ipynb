{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_MFCC(filepath):\n",
    "    audio, sample_rate = librosa.load(filepath , res_type=\"kaiser_fast\")\n",
    "    mfccs=np.mean(librosa.feature.mfcc(y=audio, sr=sample_rate , n_mfcc=100).T,axis=0)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "def calculate_accuracy(x_test, y_test, model):\n",
    "    predictions=model.predict(x_test)\n",
    "    predictions /= np.linalg.norm(predictions, axis=1, keepdims=True)\n",
    "    div=0.8 #total classes that are predicted\n",
    "    per_acc=[]\n",
    "    for i in range(0,x_test.shape[0], 10):\n",
    "        a=predictions[i]\n",
    "        label_1= np.argmax(y_test[i])\n",
    "        test_acc=[]\n",
    "        print(\"Calculating the {} th sample\".format(i//10))\n",
    "        for j in range(x_test.shape[0]):\n",
    "            b=predictions[j]\n",
    "            if np.mean(a) == np.mean(b):\n",
    "                continue\n",
    "            label_2 = np.argmax(y_test[j])\n",
    "            sim = 1- spatial.distance.cosine(a, b)\n",
    "            test_acc.append((sim, label_1, label_2))\n",
    "            \n",
    "        sorted_test = sorted(test_acc, reverse=True)\n",
    "        print(sorted_test[:9])\n",
    "        per_acc.append(sorted_test[:9])\n",
    "    \n",
    "    total_acc=[]\n",
    "    for accuracy in per_acc:\n",
    "        count=0\n",
    "        for tup in accuracy:\n",
    "            if tup[1]==tup[2]:\n",
    "                count+=1\n",
    "        acc_per_label= count/9\n",
    "        total_acc.append(acc_per_label)\n",
    "    return (sum(total_acc)*div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advance_calculate_accuracy(x_test, y_test, model, similarity=\"cosine\"):\n",
    "    predictions=model.predict(x_test)\n",
    "    predictions /= np.linalg.norm(predictions, axis=1, keepdims=True)\n",
    "    per_acc=[]\n",
    "    div=0.8 #total classes that are predicted\n",
    "    for i in range(0,x_test.shape[0], 10):\n",
    "        a=predictions[i]\n",
    "        label_1= np.argmax(y_test[i])\n",
    "        test_acc=[]\n",
    "        print(\"Calculating the {} th sample\".format(i//10))\n",
    "        for j in range(x_test.shape[0]):\n",
    "            b=predictions[j]\n",
    "            if np.mean(a) == np.mean(b):\n",
    "                continue\n",
    "            label_2 = np.argmax(y_test[j])\n",
    "            if similarity == \"cosine\":\n",
    "                sim = 1- spatial.distance.cosine(a, b)\n",
    "                test_acc.append((sim, label_1, label_2))\n",
    "            elif similarity == \"euclidean\":\n",
    "                sim = sqrt(sum(pow(x-y,2) for x, y in zip(a, b)))\n",
    "                test_acc.append((sim, label_1, label_2))\n",
    "            elif similarity == \"manhattan\":\n",
    "                sim = sum(abs(x-y) for x,y in zip(a,b))\n",
    "                test_acc.append((sim, label_1, label_2))\n",
    "           \n",
    "        if similarity==\"euclidean\" or similarity==\"manhattan\":\n",
    "            sorted_test = sorted(test_acc)\n",
    "            print(sorted_test[:9])\n",
    "            per_acc.append(sorted_test[:9])\n",
    "        else:\n",
    "            sorted_test = sorted(test_acc, reverse=True)\n",
    "            print(sorted_test[:9])\n",
    "            per_acc.append(sorted_test[:9])\n",
    "    \n",
    "    total_acc=[]\n",
    "    for accuracy in per_acc:\n",
    "        count=0\n",
    "        for tup in accuracy:\n",
    "            if tup[1]==tup[2]:\n",
    "                count+=1\n",
    "        acc_per_label= count/9\n",
    "        total_acc.append(acc_per_label)\n",
    "    return (sum(total_acc)*div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras import regularizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ArcFace(Layer):\n",
    "    def __init__(self, n_classes=10, s=30.0, m=0.50, regularizer=None, **kwargs):\n",
    "        super(ArcFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ArcFace, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[0][-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        c = K.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        # clip logits to prevent zero division when backward\n",
    "        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
    "        target_logits = tf.cos(theta + self.m)\n",
    "        # sin = tf.sqrt(1 - logits**2)\n",
    "        # cos_m = tf.cos(logits)\n",
    "        # sin_m = tf.sin(logits)\n",
    "        # target_logits = logits * cos_m - sin * sin_m\n",
    "        #\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.n_classes)\n",
    "\n",
    "\n",
    "class SphereFace(Layer):\n",
    "    def __init__(self, n_classes=10, s=30.0, m=1.35, regularizer=None, **kwargs):\n",
    "        super(SphereFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SphereFace, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[0][-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        c = K.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        # clip logits to prevent zero division when backward\n",
    "        theta = tf.acos(K.clip(logits, -1.0 + K.epsilon(), 1.0 - K.epsilon()))\n",
    "        target_logits = tf.cos(self.m * theta)\n",
    "        #\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.n_classes)\n",
    "\n",
    "\n",
    "class CosFace(Layer):\n",
    "    def __init__(self, n_classes=10, s=30.0, m=0.35, regularizer=None, **kwargs):\n",
    "        super(CosFace, self).__init__(**kwargs)\n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.regularizer = regularizers.get(regularizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(CosFace, self).build(input_shape[0])\n",
    "        self.W = self.add_weight(name='W',\n",
    "                                shape=(input_shape[0][-1], self.n_classes),\n",
    "                                initializer='glorot_uniform',\n",
    "                                trainable=True,\n",
    "                                regularizer=self.regularizer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, y = inputs\n",
    "        c = K.shape(x)[-1]\n",
    "        # normalize feature\n",
    "        x = tf.nn.l2_normalize(x, axis=1)\n",
    "        # normalize weights\n",
    "        W = tf.nn.l2_normalize(self.W, axis=0)\n",
    "        # dot product\n",
    "        logits = x @ W\n",
    "        # add margin\n",
    "        target_logits = logits - self.m\n",
    "        #\n",
    "        logits = logits * (1 - y) + target_logits * y\n",
    "        # feature re-scale\n",
    "        logits *= self.s\n",
    "        out = tf.nn.softmax(logits)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def libri_calculate_accuracy(x_test, y_test, model, similarity=\"cosine\"):\n",
    "    y_true=np.argmax(y_test, axis=1)\n",
    "    predictions=model.predict(x_test)\n",
    "    predictions /= np.linalg.norm(predictions, axis=1, keepdims=True)\n",
    "    total_prediction=0\n",
    "    per_acc=[]\n",
    "    match_count=0\n",
    "    for i in range(0,x_test.shape[0], 10):\n",
    "        a=predictions[i]\n",
    "        label_1= np.argmax(y_test[i])\n",
    "        pick_items = (list(y_true)).count(label_1) -1\n",
    "        test_acc=[]\n",
    "        print(\"Calculating the {} th sample\".format(i//10))\n",
    "        for j in range(x_test.shape[0]):\n",
    "            b=predictions[j]\n",
    "            if np.mean(a) == np.mean(b):\n",
    "                continue\n",
    "            label_2 = np.argmax(y_test[j])\n",
    "            if similarity == \"cosine\":\n",
    "                sim = 1- spatial.distance.cosine(a, b)\n",
    "                test_acc.append((sim, label_1, label_2))\n",
    "            elif similarity == \"euclidean\":\n",
    "                sim = sqrt(sum(pow(x-y,2) for x, y in zip(a, b)))\n",
    "                test_acc.append((sim, label_1, label_2))\n",
    "            elif similarity == \"manhattan\":\n",
    "                sim = sum(abs(x-y) for x,y in zip(a,b))\n",
    "                test_acc.append((sim, label_1, label_2))\n",
    "           \n",
    "        if similarity==\"euclidean\" or similarity==\"manhattan\":\n",
    "            sorted_test = sorted(test_acc)\n",
    "            print(sorted_test[:pick_items])\n",
    "            per_acc.append(sorted_test[:pick_items])\n",
    "        else:\n",
    "            sorted_test = sorted(test_acc, reverse=True)\n",
    "            print(sorted_test[:pick_items])\n",
    "            per_acc.append(sorted_test[:pick_items])\n",
    "        total_prediction+= (pick_items-1)\n",
    "    \n",
    "    for accuracy in per_acc:\n",
    "        for tup in accuracy:\n",
    "            if tup[1]==tup[2]:\n",
    "                #count+=1\n",
    "                match_count+=1\n",
    "    return (match_count/total_prediction)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
